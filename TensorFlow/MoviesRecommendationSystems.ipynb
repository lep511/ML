{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b3f6aa-b95e-46f8-8356-dd4598d84de2",
   "metadata": {},
   "source": [
    "## Sistemas de recomendación de películas con TensorFlow\n",
    "\n",
    "No es raro que al ver un vídeo (o una película) en YouTube (o Netflix) nos aparezca inmediatamente una lista de vídeos (o películas) sugeridos para ver a continuación. Lo mismo ocurre a menudo con los servicios de streaming de música digital. Uno escucha una canción en Spotify e inmediatamente recibe una lista de canciones similares, quizá del mismo género o del mismo artista.\n",
    "\n",
    "Esta lista la elabora un modelo de aprendizaje automático de recomendaciones, a menudo denominado motor/sistema de recomendaciones. Un sistema de recomendación es más que un simple aprendizaje automático. Es necesario construir un canal de datos para recopilar la información que necesita el modelo (por ejemplo, los últimos cinco vídeos que ha visto el usuario). Esta necesidad la satisface un sistema de recomendación.\n",
    "\n",
    "Un gran error es creer que los sistemas de recomendación se limitan a sugerir productos a los usuarios. No podría estar más lejos de la realidad. Los sistemas de recomendación no sólo sugieren productos a los usuarios, sino que también pueden sugerir productos a los usuarios. Por ejemplo, en aplicaciones de marketing, cuando hay una nueva promoción, un sistema de recomendación puede encontrar a los mil primeros clientes actuales más relevantes. Es lo que se denomina targeting. También, en la misma línea en la que Google maps sugiere la ruta que evita las autopistas de peaje mediante un sistema de recomendación, la respuesta inteligente en Gmail que sugiere posibles respuestas a un correo electrónico que uno acaba de recibir también se realiza mediante un sistema de recomendación. Los motores de búsqueda son otro gran ejemplo de cómo los motores de recomendación pueden ofrecer personalización. Las consultas de búsqueda tienen en cuenta la ubicación, el historial de usuario, las preferencias de cuenta y las búsquedas anteriores para garantizar que lo que se ofrece es lo más relevante para los usuarios.  \n",
    "\n",
    "Por ejemplo, escribir \"gigantes\" en la barra de búsqueda puede arrojar resultados diferentes según dónde se encuentre el usuario. Si el usuario está en Nueva York, lo más probable es que obtenga muchos resultados sobre el equipo de fútbol americano New York Giants. Sin embargo, la misma búsqueda en San Francisco podría devolver información sobre el equipo de béisbol de San Francisco. En esencia, desde el punto de vista del usuario, los sistemas de recomendación pueden ayudar a encontrar contenidos relacionados, explorar nuevos elementos y mejorar la toma de decisiones del usuario. Desde el punto de vista del productor, ayuda a aumentar el compromiso del usuario, aprender más sobre él y controlar los cambios en su comportamiento. En definitiva, los sistemas de recomendación tienen que ver con la personalización. Implica tomar un producto que funciona para todos y personalizarlo para un usuario individual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef042d8-5792-4505-ad22-ca9c2c9c78a9",
   "metadata": {},
   "source": [
    "#### Tipos de sistemas de recomendación\n",
    "Filtrado basado en el contenido:\n",
    "En este tipo de marco de recomendación se utilizan los metadatos del producto disponibles en los sistemas.  Supongamos que un usuario ha visto y valorado varias películas. A algunas les ha dado un pulgar hacia arriba y a otras un pulgar hacia abajo, y queremos saber qué película de la base de datos sugerirle a continuación.\n",
    "\n",
    "Gracias a los metadatos que tenemos sobre las películas, quizá sepamos que este usuario en concreto prefiere la ciencia ficción a las comedias de situación. Por lo tanto, empleando este tipo de sistema, podríamos utilizar esos datos para sugerir a este cliente series de ciencia ficción muy populares. Otras veces, no disponemos de las preferencias de cada usuario. Para crear un sistema de recomendación basado en el contenido, lo único que podemos necesitar es una segmentación del mercado que muestre qué películas gustan a los usuarios de distintas partes del mundo. Se argumenta que aquí no hay aprendizaje automático. Se trata de una regla sencilla que depende de que el creador del sistema de recomendación etiquete adecuadamente a las personas y los objetos. El mayor inconveniente de este método es que, para que funcione correctamente, el sistema necesita conocimientos del dominio. Aunque existen soluciones a este problema de \"arranque en frío\", nada puede superar completamente el efecto de la falta de información de formación. Además, debido a su naturaleza, este sistema sólo hace recomendaciones seguras.\n",
    "\n",
    "#### Filtrado colaborativo:\n",
    "En este método, en este caso no disponemos de metadatos sobre los productos; en su lugar, podemos inferir información sobre la similitud entre artículos y usuarios a partir de los datos de valoración. Por ejemplo, es posible que tengamos que guardar los datos de la película del usuario en una matriz con marcas de verificación que indiquen si el usuario vio la película completa, dejó un comentario sobre ella, posiblemente le dio una calificación de estrellas, o lo que sea que se utilice para determinar si a un determinado usuario le encantó una película dada. Como era de esperar, el tamaño de esta matriz es enorme. Un individuo sólo puede ver un pequeño número de estas películas porque puede haber millones o miles de millones de personas y cientos o millones de películas disponibles. Como resultado, la mayoría de estas matrices son a la vez enormes y dispersas.\n",
    "\n",
    "Para aproximarse a esta enorme matriz de usuario por elemento, el filtrado colaborativo combina dos matrices más pequeñas conocidas como factores de usuario y factores de elemento. Entonces, si queremos determinar si a un usuario concreto le gustará una determinada película, todo lo que tenemos que hacer es tomar la fila que corresponde a la película y multiplicarlas para obtener la calificación prevista. A continuación, elegimos las películas que creemos que recibirán las mejores valoraciones antes de recomendarlas a los consumidores.\n",
    "\n",
    "Lo mejor del filtrado colaborativo es que no tenemos que estar familiarizados con los metadatos de ningún elemento. Además, siempre que dispongamos de una matriz de interacción, estaremos listos y no necesitaremos segmentar por mercados a los usuarios. Dicho esto, los problemas pueden venir de la escasez y de la naturaleza descontextualizada de la función.\n",
    "\n",
    "#### Recomendaciones basadas en el conocimiento:\n",
    "En este tipo de sistema de recomendación, los datos se obtienen de encuestas a los usuarios o de la configuración introducida por los usuarios que muestra sus preferencias. Esto suele hacerse preguntando a los usuarios por sus preferencias. Una gran ventaja de las recomendaciones basadas en el conocimiento es que no necesitan datos sobre la interacción usuario-artículo. Al contrario, simplemente puede basarse en datos centrados en el usuario para relacionarlo con otros usuarios y recomendar cosas similares que les hayan gustado a esos usuarios. Además, las recomendaciones basadas en el conocimiento utilizan, en última instancia, datos de alta fidelidad, porque los usuarios de interés han informado por sí mismos de su información y sus preferencias. Como tales, es justo suponer que son ciertos. Sin embargo, en la otra cara de la moneda, puede plantearse un reto importante cuando los usuarios no se sienten cómodos compartiendo sus preferencias. La falta de datos de los usuarios puede ser un problema por cuestiones de privacidad. Debido a estos problemas de privacidad, puede ser más fácil probar otros métodos de recomendación que no estén basados en el conocimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90eee6c-6bd9-4c64-a506-7c7595bc0ee4",
   "metadata": {},
   "source": [
    "## Demo\n",
    "Como ejemplo, en este tutorial, crearás un sistema práctico de recomendación de películas utilizando TensorFlow. En esencia, TensorFlow te permite desarrollar y entrenar modelos utilizando Python (o JavaScript), y desplegar fácilmente en la nube, on-prem, en el navegador, o en el dispositivo sin importar el lenguaje de programación que utilices. Para esta demostración vamos a utilizar los cuadernos GPU gratuitos de Papersapce Gradient.\n",
    "\n",
    "Antes de continuar, es importante tener en cuenta que los sistemas de recomendación del mundo real suelen constar de dos etapas:\n",
    "\n",
    "La etapa de recuperación: Esta etapa se utiliza para seleccionar un conjunto inicial de películas candidatas de entre todas las posibles. El objetivo principal de este modelo es desterrar de forma eficaz todos los candidatos que no interesan al usuario. La etapa de recuperación suele utilizar el filtrado colaborativo.\n",
    "La fase de clasificación: Esta etapa toma los resultados obtenidos del modelo de recuperación y los ajusta para seleccionar el mejor puñado posible de recomendaciones de películas. Su tarea consiste en reducir el conjunto de películas que pueden interesar al usuario a una lista de posibles candidatas.\n",
    "Modelos de recuperación\n",
    "\n",
    "Como en todos los sistemas de recomendación basados en el filtrado colaborativo, estos modelos suelen estar compuestos por dos submodelos:\n",
    "\n",
    "* Un modelo de consulta que calcula la representación de la consulta (normalmente un vector de incrustación de dimensiones fijas) utilizando características.\n",
    "* Un modelo candidato que calcula la representación de la película candidata (un vector de igual tamaño) utilizando las características de las películas.\n",
    "\n",
    "Los resultados de los dos modelos se multiplican para obtener una puntuación de afinidad entre la película candidata y la consulta; las puntuaciones más altas expresan una mejor correspondencia entre la película candidata y la consulta. En este tutorial, vamos a construir y entrenar un sistema de recomendación utilizando el conjunto de datos Movielens con TensorFlow. El conjunto de datos Movielens es un conjunto de datos del grupo de investigación GroupLens. Contiene un conjunto de valoraciones dadas a películas por un conjunto de usuarios recogidas durante varios periodos de tiempo, dependiendo del tamaño del conjunto. Es muy popular en las investigaciones sobre sistemas de recomendación.\n",
    "\n",
    "Estos datos pueden verse de dos maneras. Pueden interpretarse como las películas que los usuarios han visto (y puntuado) y las que no. También puede interpretarse como el grado de satisfacción de los usuarios con las películas que han visto. El primer punto de vista ve el conjunto de datos como una forma de retroalimentación implícita, en la que el historial de visionado de los usuarios nos dice qué cosas prefieren ver y cuáles preferirían no ver. El segundo punto de vista puede traducir el conjunto de datos como una forma de retroalimentación explícita que puede decir aproximadamente cuánto le ha gustado una película a un usuario que la ha visto fijándose en la calificación que le ha dado.\n",
    "\n",
    "Para el sistema de recuperación, en el que el modelo predice un conjunto de películas del catálogo que es probable que vea el usuario, los datos implícitos serán tradicionalmente más útiles aquí. Por ello, trataremos Movielens como un sistema implícito. En esencia, cada película que un usuario ha visto es un ejemplo positivo, y cada película que no ha visto es un ejemplo negativo implícito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f779a-d6bd-47c4-87ae-1b7ee2bf303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets\n",
    "!pip install -q --upgrade scann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74ac05a4-4df7-4ad2-9e46-b6bbb218ca08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.platform.tf_logging.get_logger()>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa0fce8-7976-4647-bdf1-7e20449fd0ed",
   "metadata": {},
   "source": [
    "### Obtener los datos y dividirlos en un conjunto de entrenamiento y otro de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf6eedba-48b9-42c6-809d-e68a7d52426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings data.\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5594a9-c1ed-46e5-8c5a-a8786bf0bcc9",
   "metadata": {},
   "source": [
    "La variable calificaciones contiene los datos de las calificaciones, mientras que la variable películas contiene las características de todas las películas disponibles.  El conjunto de datos de valoraciones devuelve un diccionario con el identificador de la película, el identificador del usuario, la valoración asignada, la marca de tiempo, la información de la película y la información del usuario, como se muestra a continuación. Mientras que el conjunto de datos de películas contiene el id de la película, el título de la película y datos sobre los géneros a los que pertenece. Los géneros se codifican con etiquetas enteras. Es importante señalar que, dado que el conjunto de datos Movielens no tiene divisiones predefinidas, todos sus datos están bajo la división de tren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4ca6f5-842e-42c0-95bd-79ced79cd750",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cce01a14-00e4-4744-8960-598df64fd9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40adf6f1-e06f-4a3c-ac6d-833385f00033",
   "metadata": {},
   "source": [
    "Para ajustar y evaluar el modelo, lo dividiremos en un conjunto de entrenamiento y otro de evaluación. Utilizaremos una división aleatoria, colocando el 80% de las valoraciones en el conjunto de entrenamiento y el 20% en el conjunto de prueba.\n",
    "\n",
    "Llegados a este punto, nos gustaría conocer los identificadores únicos de usuario y los títulos de las películas presentes en los datos. Esto es importante porque necesitamos poder asignar los valores brutos de las características categóricas a vectores de incrustación en los modelos. Para lograrlo, necesitamos un vocabulario que asigne un valor de característica en bruto a un número entero en un rango contiguo: esto nos permite buscar las incrustaciones correspondientes en las tablas de incrustación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5107f878-da25-4ad4-a698-d26c41c2f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = movies.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576761e7-5728-4729-b4f9-5106f9f854f9",
   "metadata": {},
   "source": [
    "### Implantar un modelo de recuperación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfc03677-a63a-4f19-8fb6-5085bc90496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_user_ids, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789d44f5-d942-46cf-aff6-aa558591463d",
   "metadata": {},
   "source": [
    "Dado que los valores más altos de las dimensiones de incrustación corresponderán a modelos que pueden ser más precisos, pero también serán más lentos de ajustar y más propensos al sobreajuste, la dimensionalidad de la consulta y las representaciones candidatas se establecen en **32**. Para definir el modelo en sí, se utilizarán las capas de preprocesamiento de keras para convertir los identificadores de usuario en números enteros y, a continuación, convertirlos en incrustaciones de usuario mediante una capa de incrustación.\n",
    "\n",
    "Haremos lo mismo con la torre de candidatos a película."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0505a243-a24f-473c-b307-a2075442dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_movie_titles, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d986dfa4-cad5-4495-8932-2186d5013be6",
   "metadata": {},
   "source": [
    "En los datos de entrenamiento, observamos que tenemos pares positivos de usuario y películas. Para evaluar la calidad de nuestro modelo, compararemos la puntuación de afinidad que el modelo calcula para este par con las puntuaciones de todos los demás candidatos posibles. Esto significa que si la puntuación para el par positivo es mayor que para todos los demás candidatos, su modelo es muy preciso. Para comprobarlo, podemos utilizar la métrica tfrs.metrics.FactorizedTopK. Esta métrica tiene un argumento obligatorio: el conjunto de datos de candidatos que utilizó como negativos implícitos para la evaluación. Esto implica el conjunto de datos de películas que convertirá en incrustaciones mediante el modelo de películas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "392fb6aa-8559-4fe8-8ab9-ee5053f762c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=movies.batch(128).map(movie_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aede57-c5c4-47dd-9a09-067fceec0123",
   "metadata": {},
   "source": [
    "Además, tenemos que comprobar la pérdida utilizada para entrenar nuestro modelo. Lo bueno es que tfrs tiene varias capas de pérdida y tareas para esto. Podemos utilizar el objeto de tarea Recuperación, que es una envoltura de conveniencia que agrupa la función de pérdida y el cálculo métrico con las siguientes líneas de código.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f5c9e4c-2253-4e8e-89dc-80d7e148c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab681ce-eb26-4e35-b2f4-61f9f6dfb7db",
   "metadata": {},
   "source": [
    "Con todo eso configurado, ahora podemos ponerlo todo junto en un modelo *tfrs.models.Model*, se utilizará una clase de modelo base de tfrs para simplificar los modelos de construcción. La clase base tfrs.Model existe de tal manera que nos permite calcular tanto las pérdidas de entrenamiento como las de prueba usando el mismo método. \n",
    "\n",
    "Todo lo que tendremos que hacer es configurar los componentes en el método __init__ y luego implementar el método **compute_loss** usando las características sin procesar y devolviendo un valor de pérdida. A partir de entonces, utilizaremos el modelo base para crear el ciclo de entrenamiento adecuado para que se ajuste a su modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "926d7377-495e-4112-be69-15cf608a5658",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, user_model, movie_model):\n",
    "    super().__init__()\n",
    "    self.movie_model: tf.keras.Model = movie_model\n",
    "    self.user_model: tf.keras.Model = user_model\n",
    "    self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "    return self.task(user_embeddings, positive_movie_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea12723-26bc-49f7-bf02-10801051da6a",
   "metadata": {},
   "source": [
    "El método compute_loss comienza seleccionando las características del usuario y las pasa al modelo de usuario. A continuación, selecciona las características de la película y las pasa al modelo de película, obteniendo de vuelta los embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e49e1d4-f284-4911-a68e-fcb9f330ada0",
   "metadata": {},
   "source": [
    "### Ajuste y evaluación.\n",
    "\n",
    "Tras definir el modelo, utilizaremos las rutinas estándar de ajuste y evaluación de Keras para ajustar y evaluar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3fe9b61-972b-4511-bcfc-651167046576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 10s 556ms/step - factorized_top_k/top_1_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0022 - factorized_top_k/top_10_categorical_accuracy: 0.0066 - factorized_top_k/top_50_categorical_accuracy: 0.0580 - factorized_top_k/top_100_categorical_accuracy: 0.1238 - loss: 69836.6598 - regularization_loss: 0.0000e+00 - total_loss: 69836.6598\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 5s 510ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0120 - factorized_top_k/top_10_categorical_accuracy: 0.0271 - factorized_top_k/top_50_categorical_accuracy: 0.1424 - factorized_top_k/top_100_categorical_accuracy: 0.2646 - loss: 67494.6072 - regularization_loss: 0.0000e+00 - total_loss: 67494.6072\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 5s 512ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0178 - factorized_top_k/top_10_categorical_accuracy: 0.0387 - factorized_top_k/top_50_categorical_accuracy: 0.1781 - factorized_top_k/top_100_categorical_accuracy: 0.3070 - loss: 66302.4112 - regularization_loss: 0.0000e+00 - total_loss: 66302.4112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe749fa93a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MovielensModel(user_model, movie_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce516ce3-7fa9-4495-b6b7-8902ca1fc79a",
   "metadata": {},
   "source": [
    "Nuestro modelo se entrenará en tres épocas. Podemos ver que, a medida que el modelo se entrena, la pérdida disminuye y se actualiza un conjunto de métricas de recuperación top-k. \n",
    "\n",
    "Estas métricas nos permiten saber si el verdadero positivo se encuentra en el top-k de elementos recuperados de todo el conjunto de candidatos. Tenga en cuenta que, en este tutorial, evaluaremos las métricas tanto durante el entrenamiento como durante la evaluación. Debido a que esto puede ser bastante lento con grandes conjuntos de candidatos, puede ser prudente desactivar el cálculo de métricas en el entrenamiento, y sólo ejecutarlo en la evaluación.\n",
    "\n",
    "Por último, podemos evaluar nuestro modelo en el conjunto de pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a91f4dd4-e3a1-4e05-ac14-84752c7d8be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 296ms/step - factorized_top_k/top_1_categorical_accuracy: 9.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0107 - factorized_top_k/top_10_categorical_accuracy: 0.0218 - factorized_top_k/top_50_categorical_accuracy: 0.1248 - factorized_top_k/top_100_categorical_accuracy: 0.2374 - loss: 31075.7692 - regularization_loss: 0.0000e+00 - total_loss: 31075.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0009500000160187483,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.010700000450015068,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.021800000220537186,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.12475000321865082,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.2373500019311905,\n",
       " 'loss': 28241.87109375,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 28241.87109375}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ccd801-c077-43f0-888d-16206d629a84",
   "metadata": {},
   "source": [
    "Hay que señalar que el rendimiento del conjunto de pruebas no es tan bueno como el del conjunto de entrenamiento. La razón no es descabellada. Nuestro modelo funcionará mejor con los datos que ha visto antes. Además, el modelo sólo vuelve a recomendar algunas de las películas que los usuarios ya han visto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e24cf9e-d650-4e8d-b752-1e5289f013a2",
   "metadata": {},
   "source": [
    "### Haciendo predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370da5f8-de66-41ee-a768-f6c6c67b1fc3",
   "metadata": {},
   "source": [
    "Ya que tenemos un modelo funcionando, podemos empezar a hacer predicciones. Para ello utilizaremos la capa *tfrs.layers.factorized_top_k.BruteForce* La utilizaremos para tomar las características de consulta en bruto y luego recomendar películas de todo el conjunto de datos de películas. Finalmente, obtendremos nuestras recomendaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7397466b-0893-4015-b2b0-4895670838fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 46: [b'Game, The (1997)' b'Welcome To Sarajevo (1997)' b'Amistad (1997)']\n"
     ]
    }
   ],
   "source": [
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    ")\n",
    "\n",
    "_, titles = index(tf.constant([\"46\"]))\n",
    "print(f\"Recommendations for user 46: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bfed1a-97e3-4b83-9997-96a738d7b21b",
   "metadata": {},
   "source": [
    "En el bloque de código anterior, obtendremos la recomendación para el *Usuario 46*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d461f2-587e-4b52-9ef4-b5745dbf8faa",
   "metadata": {},
   "source": [
    "### Exportar el modelo\n",
    "\n",
    "Intuitivamente, la capa de Fuerza Bruta es demasiado lenta para servir un modelo con muchos candidatos. Este proceso se acelerará utilizando un índice de recuperación aproximado. Mientras que el servicio en el modelo de recuperación tiene dos componentes (es decir, un modelo de consulta de servicio y un modelo de candidato de servicio), con tfrs, ambos componentes pueden empaquetarse en un único modelo que podemos exportar. Este modelo toma el identificador de usuario en bruto y devuelve los títulos de las mejores películas para ese usuario. Para ello, vamos a exportar el modelo a un formato SavedModel que hace que sea posible servir utilizando TensorFlow Serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06e5389d-d050-4d75-8362-c08c5e02ce97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [b'Rudy (1993)' b'Bridges of Madison County, The (1995)'\n",
      " b'101 Dalmatians (1996)']\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    path = os.path.join(\"./\", \"model\")\n",
    "    tf.saved_model.save(index, path)\n",
    "    loaded = tf.saved_model.load(path)\n",
    "    scores, titles = loaded([\"42\"])\n",
    "    print(f\"Recommendations: {titles[0][:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f73d39a-bf30-41d7-8ccc-01a133b675bc",
   "metadata": {},
   "source": [
    "Para obtener recomendaciones eficientes de millones de películas candidatas, utilizaremos una dependencia opcional de TFRS conocida como la capa TFRS scann. El paquete se instaló por separado al principio del tutorial llamando a *!pip install -q scann*. Esta capa puede realizar búsquedas aproximadas que harán que la recuperación sea ligeramente menos precisa, mientras que se mantiene órdenes de magnitud más rápida en grandes conjuntos de candidatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f138f76-e34a-474c-b7f7-83451026901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 42: [b'Grumpier Old Men (1995)' b'Aristocats, The (1970)'\n",
      " b\"Preacher's Wife, The (1996)\"]\n"
     ]
    }
   ],
   "source": [
    "scann_index = tfrs.layers.factorized_top_k.ScaNN(model.user_model)\n",
    "scann_index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    ")\n",
    "\n",
    "_, titles = scann_index(tf.constant([\"42\"]))\n",
    "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683bc98f-a8d7-4a58-82b7-ed388dbc75b3",
   "metadata": {},
   "source": [
    "Por último, exportaremos el modelo de consulta, guardaremos el índice, lo volveremos a cargar y le pasaremos un identificador de usuario para obtener los títulos de películas más populares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1113654-146c-46d8-a0ea-df7aa99df7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [b'Rudy (1993)' b'Bridges of Madison County, The (1995)'\n",
      " b'101 Dalmatians (1996)']\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "  path = os.path.join(\"./\", \"model_final\")\n",
    "\n",
    "  tf.saved_model.save(\n",
    "      index,\n",
    "      path,\n",
    "      options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n",
    "  )\n",
    "  loaded = tf.saved_model.load(path)\n",
    "\n",
    "  scores, titles = loaded([\"42\"])\n",
    "\n",
    "  print(f\"Recommendations: {titles[0][:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6792574-1f73-426e-8280-25c6322937ad",
   "metadata": {},
   "source": [
    "### Modelos de clasificación\n",
    "\n",
    "Con el modelo de clasificación, los dos primeros pasos (es decir, importar las bibliotecas necesarias y dividir los datos en conjuntos de entrenamiento y de prueba) son exactamente iguales a los del modelo de recuperación.\n",
    "\n",
    "En el caso del modelo de clasificación, las limitaciones de eficacia son muy distintas a las del modelo de recuperación. Por tanto, tenemos más libertad a la hora de elegir la arquitectura.  Para las tareas de clasificación se suele utilizar un modelo compuesto por múltiples capas densas apiladas. A continuación lo implementaremos:\n",
    "\n",
    "*Nota: Este modelo tomará los ID de usuario y los títulos de las películas como datos de entrada y, a continuación, emitirá una valoración prevista.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b16ca9a-466f-4015-9179-5d65f0625a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # Compute embeddings for users\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for movies\n",
    "    self.movie_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute predictions\n",
    "    self.ratings = tf.keras.Sequential([\n",
    "      # Learn multiple dense layers.\n",
    "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      # Make rating predictions in the final layer.\n",
    "      tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  def call(self, inputs):\n",
    "\n",
    "    user_id, movie_title = inputs\n",
    "\n",
    "    user_embedding = self.user_embeddings(user_id)\n",
    "    movie_embedding = self.movie_embeddings(movie_title)\n",
    "\n",
    "    return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323c1bbf-68a5-4166-b7b7-360070fb2f03",
   "metadata": {},
   "source": [
    "Para evaluar la pérdida utilizada para entrenar nuestro modelo, utilizaremos el objeto de tarea Ranking que combina la función de pérdida con el cálculo métrico.  Lo utilizaremos junto con la pérdida MeanSquaredError Keras para predecir las valoraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2c2e0e6-210f-4280-a363-7f0d64ef3645",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Ranking(\n",
    "  loss = tf.keras.losses.MeanSquaredError(),\n",
    "  metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f59b00e-fb92-44ab-a880-e82b9d00b449",
   "metadata": {},
   "source": [
    "Al reunirlo todo en un modelo de clasificación completo, tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8001536f-3766-432c-9c1c-8e57acf2d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.ranking_model: tf.keras.Model = RankingModel()\n",
    "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "      loss = tf.keras.losses.MeanSquaredError(),\n",
    "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    return self.ranking_model(\n",
    "        (features[\"user_id\"], features[\"movie_title\"]))\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    labels = features.pop(\"user_rating\")\n",
    "\n",
    "    rating_predictions = self(features)\n",
    "    return self.task(labels=labels, predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a60275-c9d7-4416-95fa-3363f8f4126f",
   "metadata": {},
   "source": [
    "### Ajuste y evaluación del modelo de clasificación\n",
    "\n",
    "Una vez definido el modelo, utilizaremos las rutinas estándar de ajuste y evaluación de Keras para ajustar y evaluar el modelo de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca39d7f-16cd-44c1-9a6d-37f728af2aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "model.fit(cached_train, epochs=3)\n",
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c1ac26-1ca8-4052-b9cb-c107cd731932",
   "metadata": {},
   "source": [
    "Con el modelo entrenado en tres épocas, probaremos el modelo de clasificación calculando predicciones para un conjunto de películas y clasificándolas en función de las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a142a70-bd51-4928-98d7-d303569aed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratings = {}\n",
    "test_movie_titles = [\"M*A*S*H (1970)\", \"Dances with Wolves (1990)\", \"Speed (1994)\"]\n",
    "for movie_title in test_movie_titles:\n",
    "  test_ratings[movie_title] = model({\n",
    "      \"user_id\": np.array([\"42\"]),\n",
    "      \"movie_title\": np.array([movie_title])\n",
    "  })\n",
    "\n",
    "print(\"Ratings:\")\n",
    "for title, score in sorted(test_ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "  print(f\"{title}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d542924-4543-4252-8856-10c0f2f60ff1",
   "metadata": {},
   "source": [
    "### Exportar para servir y convertir el modelo a TensorFlow Lite\n",
    "\n",
    "Un sistema de recomendación no sirve de nada si no puede ser utilizado por los usuarios. Por ello, debemos exportar el modelo para servirlo. Después, podemos cargarlo de nuevo y realizar predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1339e9-9dfa-44de-b496-ffcae27f794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, \"export\")\n",
    "loaded = tf.saved_model.load(\"export\")\n",
    "\n",
    "loaded({\"user_id\": np.array([\"42\"]), \"movie_title\": [\"Speed (1994)\"]}).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00568fc7-7070-42aa-8752-ce0e30518178",
   "metadata": {},
   "source": [
    "Para mejorar la privacidad del usuario y reducir la latencia, utilizaremos TensorFlow Lite para ejecutar el modelo de clasificación entrenado en los dispositivos, a pesar de que TensorFlow Recommenders está pensado principalmente para realizar recomendaciones del lado del servidor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a8b61-aa77-46d0-ae7d-fd8c2f9a8f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"export\")\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c99a522-5696-4909-a8a5-86671af3e3ab",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "Ahora deberíamos saber qué es un recomendador, cómo funciona, la diferencia entre feedback implícito y explícito y cómo construir un sistema de recomendación con algoritmos de filtrado colaborativo. Por nuestra cuenta, podemos modificar ajustes de la red como la dimensión de las capas ocultas para ver los cambios correspondientes. Como regla general, estas dimensiones dependen de la complejidad de las funciones que queremos aproximar. Si las capas ocultas son demasiado grandes, nuestro modelo corre el riesgo de sobreajustarse y, por tanto, de perder la capacidad de generalizar bien en el conjunto de pruebas. Por el contrario, si las capas ocultas son demasiado pequeñas, la red neuronal se quedará corta de parámetros para ajustarse bien a los datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
