{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe2b397-d3a0-4746-99f5-01e8b90a6c42",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Los árboles de decisión lo dejan a usted con una decisión difícil. Un árbol profundo con muchas hojas tendrá un rendimiento excesivo porque cada predicción procede de los datos históricos de sólo las pocas casas de su hoja. Pero un árbol poco profundo con pocas hojas tendrá un mal rendimiento porque no consigue captar tantas distinciones en los datos brutos.\n",
    "\n",
    "Incluso las técnicas de modelización más sofisticadas de hoy en día se enfrentan a esta tensión entre el subajuste y el sobreajuste. Sin embargo, muchos modelos tienen ideas inteligentes que pueden conducir a un mejor rendimiento. Veremos el bosque aleatorio como ejemplo.\n",
    "\n",
    "El bosque aleatorio utiliza muchos árboles, y hace una predicción promediando las predicciones de cada árbol componente. Por lo general, tiene una precisión de predicción mucho mayor que la de un solo árbol de decisión y funciona bien con parámetros predeterminados. Si sigues modelando, puedes aprender más modelos con un rendimiento aún mejor, pero muchos de ellos son sensibles a la obtención de los parámetros correctos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b13f4b-fbca-4ec0-b09b-fc1664314cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "# Load data\n",
    "melbourne_data = pd.read_csv('melb_data.csv') \n",
    "# Filter rows with missing values\n",
    "melbourne_data = melbourne_data.dropna(axis=0)\n",
    "# Choose target and features\n",
    "y = melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "# The split is based on a random number generator. Supplying a numeric value to\n",
    "# the random_state argument guarantees we get the same split every time we\n",
    "# run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a6684-28e7-4f39-a32b-235b89cbf1f5",
   "metadata": {},
   "source": [
    "Construimos un modelo de bosque aleatorio de forma similar a como construimos un árbol de decisión en scikit-learn - esta vez usando la clase *RandomForestRegressor* en lugar de *DecisionTreeRegressor*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e0a456-74d1-4ca1-9237-98508c328d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185570.9379721684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e8b385-7e70-47ea-a66e-44eede41e952",
   "metadata": {},
   "source": [
    "Es probable que se pueda mejorar aún más, pero es una gran mejora respecto al mejor error del árbol de decisión de 250.000. Hay parámetros que permiten cambiar el rendimiento del Bosque Aleatorio de la misma manera que cambiamos la profundidad máxima del árbol de decisión simple. Pero una de las mejores características de los modelos **Random Forest** es que generalmente funcionan razonablemente bien incluso sin este ajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffb6613-6f58-4db5-ba4b-5ec1796f9d2e",
   "metadata": {},
   "source": [
    "## Ejemplo\n",
    "\n",
    "### *DecisionTreeRegressor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "522bb78f-61f2-46e8-9144-8489bc683f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE when not specifying max_leaf_nodes: 29,653\n",
      "Validation MAE for best value of max_leaf_nodes: 27,283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "home_data = pd.read_csv(\"iowa_houses_train.csv\")\n",
    "# Create target object and call it y\n",
    "y = home_data.SalePrice\n",
    "# Create X\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[features]\n",
    "\n",
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "# Fit Model\n",
    "iowa_model.fit(train_X, train_y)\n",
    "\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
    "\n",
    "# Using best value for max_leaf_nodes\n",
    "iowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\n",
    "iowa_model.fit(train_X, train_y)\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c107377-9564-426d-ba02-4126d634e3cd",
   "metadata": {},
   "source": [
    "### *RandomForestRegressor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23b33696-7dc1-4822-ae6a-8ee5a748b28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE for best value of max_leaf_nodes: 22,041\n"
     ]
    }
   ],
   "source": [
    "# Define the model. Set random_state to 1\n",
    "rf_model = RandomForestRegressor(max_leaf_nodes=100, random_state=1)\n",
    "\n",
    "# fit your model\n",
    "rf_model.fit(train_X, train_y)\n",
    "\n",
    "# Calculate the mean absolute error of your Random Forest model on the validation data\n",
    "rf_val_predictions = rf_model.predict(val_X)\n",
    "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n",
    "print(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(rf_val_mae))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
