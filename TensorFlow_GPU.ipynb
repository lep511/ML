{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9337144-4ff9-485c-9c48-54137790f36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80337344-08d8-4d0e-ace9-3121ac11b9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c47cc0f-ae32-4810-b354-eec31a33d909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f2247d1-820a-49eb-bb7f-eb2a099463c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "924bd09b-64e3-49d0-8c7d-14a9684218e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aadf9e30-82e3-4dee-8541-d2f0266a1fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Units logs\n",
    "log_device_placement = True\n",
    "\n",
    "# Num of multiplications to perform\n",
    "n = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63390a2-c048-4ce5-bf42-3a172fda803f",
   "metadata": {},
   "source": [
    "Example: compute A^n + B^n on 2 GPUs\n",
    "Results on 8 cores with 2 GTX-980:\n",
    " * Single GPU computation time: 0:00:11.277449\n",
    " * Multi GPU computation time: 0:00:07.131701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9266a852-ba04-4808-aa33-cc815a81f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random large matrix\n",
    "A = np.random.rand(10000, 10000).astype('float32')\n",
    "B = np.random.rand(10000, 10000).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb8a66a7-a14c-4f9f-b401-3db188c12c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph to store results\n",
    "c1 = []\n",
    "c2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfd17b89-fa61-40a0-be76-786d2c0fadb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matpow(M, n):\n",
    "    if n < 1: #Abstract cases where n < 1\n",
    "        return M\n",
    "    else:\n",
    "        return tf.matmul(M, matpow(M, n-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42bd58ce-b482-452a-9485-c48b09d80e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccc80858-50aa-4b1b-bdac-2bbdd6459bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n",
      "\n",
      "MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_2: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_3: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_4: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_5: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_6: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_7: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_8: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_9: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_10: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_11: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_12: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_13: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_14: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_15: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_16: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_17: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_18: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "MatMul_19: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "AddN: (AddN): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Placeholder: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Placeholder_1: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 14:43:02.480792: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2022-03-19 14:43:02.766044: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2022-03-19 14:43:03.060468: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 400000000 exceeds 10% of free system memory.\n",
      "2022-03-19 14:43:03.061610: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 400000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single GPU computation time: 0:00:10.475407\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Single GPU computing\n",
    "'''\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.placeholder(tf.float32, [10000, 10000])\n",
    "    b = tf.placeholder(tf.float32, [10000, 10000])\n",
    "    # Compute A^n and B^n and store results in c1\n",
    "    c1.append(matpow(a, n))\n",
    "    c1.append(matpow(b, n))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "  sum = tf.add_n(c1) #Addition of all elements in c1, i.e. A^n + B^n\n",
    "\n",
    "t1_1 = datetime.datetime.now()\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=log_device_placement)) as sess:\n",
    "    # Run the op.\n",
    "    sess.run(sum, {a:A, b:B})\n",
    "t2_1 = datetime.datetime.now()\n",
    "\n",
    "print(\"Single GPU computation time: \" + str(t2_1-t1_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
